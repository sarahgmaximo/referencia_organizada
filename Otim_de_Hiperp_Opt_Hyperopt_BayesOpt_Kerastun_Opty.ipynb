Exemplo de uso do Optuna para otimizar um modelo XGBoost

Copiar código
import optuna
import xgboost as xgb
from sklearn.datasets import load_boston
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

# Carregar dados de exemplo
boston = load_boston()
X, y = boston.data, boston.target

# Dividir os dados em treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Função de objetivo para otimização com Optuna
def objective(trial):
    # Definir hiperparâmetros para otimização
    params = {
        'objective': 'reg:squarederror',
        'n_estimators': trial.suggest_int('n_estimators', 50, 200),
        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.1),
        'max_depth': trial.suggest_int('max_depth', 3, 10),
        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),
        'subsample': trial.suggest_uniform('subsample', 0.1, 1.0),
        'gamma': trial.suggest_uniform('gamma', 0, 1)
    }

    # Treinar modelo XGBoost com hiperparâmetros otimizados
    model = xgb.XGBRegressor(**params)
    model.fit(X_train, y_train)

    # Realizar previsões no conjunto de teste
    y_pred = model.predict(X_test)

    # Calcular o erro médio quadrático como métrica de avaliação
    mse = mean_squared_error(y_test, y_pred)

    return mse

# Criação e otimização do estudo com Optuna
study = optuna.create_study(direction='minimize')
study.optimize(objective, n_trials=100)


import xgboost as xgb
from hyperopt import fmin, hp, tpe, Trials
from sklearn.datasets import load_boston
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

# Carrega o conjunto de dados de Boston
boston = load_boston()

# Separa os dados em conjuntos de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.2, random_state=42)

# Define os hiperparâmetros a serem otimizados pelo Hyperopt
space = {
    'n_estimators': hp.quniform('n_estimators', 100, 1000, 100),
    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),
    'max_depth': hp.quniform('max_depth', 3, 9, 1),
    'subsample': hp.uniform('subsample', 0.5, 1.0),
    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1.0),
    'gamma': hp.uniform('gamma', 0, 5)
}

# Define a função de objetivo a ser maximizada pelo Hyperopt
def objective(params):
    # Cria o modelo XGBoost com os parâmetros definidos pelo Hyperopt
    model = xgb.XGBRegressor(**params, random_state=42)

    # Treina o modelo
    model.fit(X_train, y_train)

    # Faz a predição no conjunto de teste
    y_pred = model.predict(X_test)

    # Calcula o erro médio quadrático
    mse = mean_squared_error(y_test, y_pred)

    return mse

# Cria um objeto Trials para armazenar os resultados das tentativas
trials = Trials()

# Otimiza os hiperparâmetros do modelo XGBoost usando o algoritmo TPE do Hyperopt
best = fmin(fn=objective,
            space=space,
            algo=tpe.suggest,
            max_evals=100,
            trials=trials)

# Exibe os melhores parâmetros encontrados pelo Hyperopt
print('Melhores parâmetros:', best)


import xgboost as xgb
from bayes_opt import BayesianOptimization
from sklearn.datasets import load_boston
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split

# Carrega o conjunto de dados de Boston
boston = load_boston()

# Separa os dados em conjuntos de treinamento e teste
X_train, X_test, y_train, y_test = train_test_split(boston.data, boston.target, test_size=0.2, random_state=42)

# Define a função de objetivo a ser maximizada pelo BayesianOptimization
def objective(n_estimators, learning_rate, max_depth, subsample, colsample_bytree, gamma):
    # Cria o modelo XGBoost com os parâmetros definidos pelo BayesianOptimization
    model = xgb.XGBRegressor(n_estimators=int(n_estimators),
                              learning_rate=learning_rate,
                              max_depth=int(max_depth),
                              subsample=subsample,
                              colsample_bytree=colsample_bytree,
                              gamma=gamma,
                              random_state=42)

    # Treina o modelo
    model.fit(X_train, y_train)

    # Faz a predição no conjunto de teste
    y_pred = model.predict(X_test)

    # Calcula o erro médio quadrático
    mse = mean_squared_error(y_test, y_pred)

    return -mse  # Minimiza o MSE, por isso o sinal negativo

# Define os limites dos hiperparâmetros a serem otimizados pelo BayesianOptimization
pbounds = {'n_estimators': (100, 1000),
           'learning_rate': (0.01, 0.3),
           'max_depth': (3, 9),
           'subsample': (0.5, 1.0),
           'colsample_bytree': (0.5, 1.0),
           'gamma': (0, 5)}

# Cria o objeto BayesianOptimization com a função de objetivo e os limites dos hiperparâmetros
optimizer = BayesianOptimization(f=objective, pbounds=pbounds)

# Realiza a otimização dos hiperparâmetros
optimizer.maximize(init_points=10, n_iter=50)  # Realiza 10 pontos de inicialização e 50 iterações de otimização

# Exibe os melhores parâmetros encontrados pelo BayesianOptimization
best_params = optimizer.max['params']
print('Melhores parâmetros:', best_params)

# Exemplo de como usar o módulo Keras Tuner para otimizar os hiperparâmetros de um modelo de rede neural usando o framework Keras em Python

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.datasets import mnist
from tensorflow.keras.layers import Dense, Dropout
from tensorflow.keras.models import Sequential
from kerastuner import HyperModel, RandomSearch
from kerastuner.engine.hyperparameters import HyperParameters

# Define a classe do modelo para otimização pelo Keras Tuner
class MyHyperModel(HyperModel):
    def __init__(self, input_shape, num_classes):
        self.input_shape = input_shape
        self.num_classes = num_classes

    def build(self, hp):
        model = Sequential()
        model.add(Dense(units=hp.Int('units1', min_value=32, max_value=512, step=32),
                        activation='relu', input_shape=self.input_shape))
        model.add(Dropout(rate=hp.Float('dropout1', min_value=0.1, max_value=0.5, step=0.1)))
        model.add(Dense(units=hp.Int('units2', min_value=32, max_value=512, step=32),
                        activation='relu'))
        model.add(Dropout(rate=hp.Float('dropout2', min_value=0.1, max_value=0.5, step=0.1)))
        model.add(Dense(self.num_classes, activation='softmax'))
        return model

# Carrega o conjunto de dados MNIST
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Normaliza os dados de entrada
x_train = x_train.astype('float32') / 255.0
x_test = x_test.astype('float32') / 255.0

# Converte as classes em vetores one-hot
num_classes = 10
y_train = keras.utils.to_categorical(y_train, num_classes)
y_test = keras.utils.to_categorical(y_test, num_classes)

# Define a função de objetivo a ser otimizada pelo Keras Tuner
def objective(hp):
    model = MyHyperModel(input_shape=(784,), num_classes=num_classes)
    model.build(hp)

    # Compila o modelo
    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])),
                  loss='categorical_crossentropy',
                  metrics=['accuracy'])

    # Treina o modelo
    model.fit(x_train, y_train, batch_size=hp.Int('batch_size', min_value=32, max_value=128, step=32),
              epochs=hp.Int('epochs', min_value=10, max_value=50, step=10), verbose=0)

    # Avalia o modelo
    _, accuracy = model.evaluate(x_test, y_test, verbose=0)
    return accuracy

# Define o objeto RandomSearch do Keras Tuner com a função de objetivo
tuner = RandomSearch(
    objective=objective,
    max_trials=10,  # Número de iterações de otimização
    directory='keras_tuner',  # Diretório para salvar os resultados
    project_name='mnist')  # Nome do projeto

# Realiza a otimização dos hiperparâmetros
tuner.search(x_train, y_train, epochs=10, validation_split=0.1)  # Realiza 10 épocas de busca

# Exibe os melhores hiperparâmetros encontrados pelo Keras Tuner
best_hps





import numpy as np
import sklearn.datasets
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import cross_val_score
import optunity

# Define a função de objetivo a ser otimizada pelo Optunity
def objective(x_train, y_train, x_test, y_test, **kwargs):
    # Define o modelo de regressão com os hiperparâmetros a serem otimizados
    model = RandomForestRegressor(n_estimators=int(kwargs['n_estimators']),
                                   max_depth=int(kwargs['max_depth']),
                                   min_samples_split=int(kwargs['min_samples_split']),
                                   min_samples_leaf=int(kwargs['min_samples_leaf']),
                                   max_features=int(kwargs['max_features']))

    # Calcula o score de validação cruzada com os hiperparâmetros otimizados
    score = cross_val_score(model, x_train, y_train, cv=3, n_jobs=-1).mean()

    # Treina o modelo com os hiperparâmetros otimizados
    model.fit(x_train, y_train)

    # Calcula o score de teste com os hiperparâmetros otimizados
    test_score = model.score(x_test, y_test)

    return test_score

# Carrega o conjunto de dados Boston House Prices
data = sklearn.datasets.load_boston()
x, y = data['data'], data['target']

# Divide os dados em conjunto de treino e teste
test_size = int(0.2 * len(x))
indices = np.arange(len(x))
np.random.shuffle(indices)
train_indices, test_indices = indices[test_size:], indices[:test_size]
x_train, y_train = x[train_indices], y[train_indices]
x_test, y_test = x[test_indices], y[test_indices]

# Define o espaço de busca dos hiperparâmetros com Optunity
search_space = {'n_estimators': [50, 200],
                'max_depth': [2, 10],
                'min_samples_split': [2, 10],
                'min_samples_leaf': [1, 10],
                'max_features': [1, x_train.shape[1]]}

# Realiza a otimização dos hiperparâmetros com Optunity
optimal_pars, _, _ = optunity.maximize_structured(objective, search_space=search_space, num_evals=50,
                                                   x_train=x_train, y_train=y_train, x_test=x_test, y_test=y_test)

# Exibe os melhores hiperparâmetros encontrados pelo Optunity
print('Best parameters: ' + str(optimal_pars))
